{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g2RQRSltgja"
      },
      "source": [
        "# Full DL Solution\n",
        "---\n",
        "### **Case Study:** Stroke Prediction\n",
        "\n",
        "**Objective:** The goal of this project is to walk you through a case study where you can apply the deep learning concepts that you learned about during the week. By the end of this project, you would have developed a solution that predicts if a person will have a stroke or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCD88NxJjFo"
      },
      "source": [
        "**Dataset Explanation:** We will be using the stroke dataset. Its features are:\n",
        "\n",
        "\n",
        "* **id:** unique identifier\n",
        "* **gender:** \"Male\", \"Female\" or \"Other\"\n",
        "* **age:** age of the patient\n",
        "* **hypertension:** 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
        "* **heart_disease:** 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
        "* **ever_married:** \"No\" or \"Yes\"\n",
        "* **work_type:** \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
        "* **Residence_type:** \"Rural\" or \"Urban\"\n",
        "* **avg_glucose_level:** average glucose level in blood\n",
        "* **bmi:** body mass index\n",
        "* **smoking_status:** \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
        "* **stroke:** 1 if the patient had a stroke or 0 if not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBvX5nCYt8cT"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaPfsfvXK2_0"
      },
      "source": [
        "We start by importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oK92M0m-ezbE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mMQuUG7OtfrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-RxAH5auFFy"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_jj2t6zK6zy"
      },
      "source": [
        "We load the dataset from a csv file, and see its first rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UQVo1CAJt7s8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0   9046    Male  67.0             0              1          Yes   \n",
              "1  51676  Female  61.0             0              0          Yes   \n",
              "2  31112    Male  80.0             0              1          Yes   \n",
              "3  60182  Female  49.0             0              0          Yes   \n",
              "4   1665  Female  79.0             1              0          Yes   \n",
              "\n",
              "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0        Private          Urban             228.69  36.6  formerly smoked   \n",
              "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2        Private          Rural             105.92  32.5     never smoked   \n",
              "3        Private          Urban             171.23  34.4           smokes   \n",
              "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
              "\n",
              "   stroke  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = './data/Stroke-Data.csv'\n",
        "data = pd.read_csv(path)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6gAyBGtubI7"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_93CvuLF3j"
      },
      "source": [
        "Now we start the exploratory data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2925yVCdud0a"
      },
      "source": [
        "### Shape of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ0hWvVALJy4"
      },
      "source": [
        "First thing we need to know the shape of our data\n",
        "\n",
        "**Question 1:** How many examples and features do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8pvWR3PKuQEy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples:  5110\n",
            "Number of features:  12\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nrows,ncols = data.shape\n",
        "print(\"Number of examples: \", nrows)\n",
        "print(\"Number of features: \", ncols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUy4oI5xukRr"
      },
      "source": [
        "### Types of different Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1q10ievLTTs"
      },
      "source": [
        "**Question 2:** Check the type of each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_8snoohouhUP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                     int64\n",
              "gender                object\n",
              "age                  float64\n",
              "hypertension           int64\n",
              "heart_disease          int64\n",
              "ever_married          object\n",
              "work_type             object\n",
              "Residence_type        object\n",
              "avg_glucose_level    float64\n",
              "bmi                  float64\n",
              "smoking_status        object\n",
              "stroke                 int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkrEh6RYygms"
      },
      "source": [
        "### Dealing with categorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kBYl7ItLGt"
      },
      "source": [
        "**Question 3:** Use the .value_counts() functions to walk through the categorical variables that we have to see the categories and the counts of each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DlSfSQ35ykgc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "smoking_status\n",
              "never smoked       1892\n",
              "Unknown            1544\n",
              "formerly smoked     885\n",
              "smokes              789\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smoking_types = data['smoking_status'].value_counts()\n",
        "smoking_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yg0xlLNUy7AF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Residence_type\n",
              "Urban    2596\n",
              "Rural    2514\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "residence_types = data['Residence_type'].value_counts()\n",
        "residence_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T72r_mkrzF9V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "work_type\n",
              "Private          2925\n",
              "Self-employed     819\n",
              "children          687\n",
              "Govt_job          657\n",
              "Never_worked       22\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "work_types = data['work_type'].value_counts()\n",
        "work_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z0kpR57LzQE9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ever_married\n",
              "Yes    3353\n",
              "No     1757\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "married_types = data['ever_married'].value_counts()\n",
        "married_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fQIoAs8y3igG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hypertension\n",
              "0    4612\n",
              "1     498\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hypertension = data['hypertension'].value_counts()\n",
        "hypertension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xEhNH46j3p3Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "heart_disease\n",
              "0    4834\n",
              "1     276\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_disease = data['heart_disease'].value_counts()\n",
        "heart_disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8cI7uJvA3Njv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "stroke\n",
              "0    4861\n",
              "1     249\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stroke = data['stroke'].value_counts()\n",
        "stroke"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jFIiKPvllld"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsQQj-wVlkjS"
      },
      "source": [
        "### Dealing with Nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdlRc672lgI4"
      },
      "source": [
        "**Question 4:** The bmi column contains nulls. Fill it with the appropriate measure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7UDrnGK6lYiE"
      },
      "outputs": [],
      "source": [
        "data['bmi'].fillna(data['bmi'].mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21da4C_Bzd-u"
      },
      "source": [
        "#### Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaNk4gWCLqe4"
      },
      "source": [
        "**Question 5:** Here you have to encode those categorical variables to be able to use them to train your DL model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6nJtOvxdzi_G"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "data['smoking_status'] = encoder.fit_transform(data['smoking_status'])\n",
        "data['Residence_type'] = encoder.fit_transform(data['Residence_type'])\n",
        "data['work_type'] = encoder.fit_transform(data['work_type'])\n",
        "data['ever_married'] = encoder.fit_transform(data['ever_married'])\n",
        "data['gender'] = encoder.fit_transform(data['gender'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GOfAgt4M-Q"
      },
      "source": [
        "### Normalizing Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPpkMCXELwty"
      },
      "source": [
        "**Question 6:** Normalize the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BtI_XA-m33Bx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500197</td>\n",
              "      <td>0.207143</td>\n",
              "      <td>0.526692</td>\n",
              "      <td>0.097456</td>\n",
              "      <td>0.054012</td>\n",
              "      <td>0.656164</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>0.508023</td>\n",
              "      <td>0.235563</td>\n",
              "      <td>0.212981</td>\n",
              "      <td>0.458969</td>\n",
              "      <td>0.048728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.290392</td>\n",
              "      <td>0.246522</td>\n",
              "      <td>0.276033</td>\n",
              "      <td>0.296607</td>\n",
              "      <td>0.226063</td>\n",
              "      <td>0.475034</td>\n",
              "      <td>0.272573</td>\n",
              "      <td>0.499985</td>\n",
              "      <td>0.209046</td>\n",
              "      <td>0.088179</td>\n",
              "      <td>0.357178</td>\n",
              "      <td>0.215320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.242535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304199</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102137</td>\n",
              "      <td>0.154639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.505880</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.169721</td>\n",
              "      <td>0.207331</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.749455</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.743652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.272228</td>\n",
              "      <td>0.257732</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id       gender          age  hypertension  heart_disease  \\\n",
              "count  5110.000000  5110.000000  5110.000000   5110.000000    5110.000000   \n",
              "mean      0.500197     0.207143     0.526692      0.097456       0.054012   \n",
              "std       0.290392     0.246522     0.276033      0.296607       0.226063   \n",
              "min       0.000000     0.000000     0.000000      0.000000       0.000000   \n",
              "25%       0.242535     0.000000     0.304199      0.000000       0.000000   \n",
              "50%       0.505880     0.000000     0.548340      0.000000       0.000000   \n",
              "75%       0.749455     0.500000     0.743652      0.000000       0.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000       1.000000   \n",
              "\n",
              "       ever_married    work_type  Residence_type  avg_glucose_level  \\\n",
              "count   5110.000000  5110.000000     5110.000000        5110.000000   \n",
              "mean       0.656164     0.541928        0.508023           0.235563   \n",
              "std        0.475034     0.272573        0.499985           0.209046   \n",
              "min        0.000000     0.000000        0.000000           0.000000   \n",
              "25%        0.000000     0.500000        0.000000           0.102137   \n",
              "50%        1.000000     0.500000        1.000000           0.169721   \n",
              "75%        1.000000     0.750000        1.000000           0.272228   \n",
              "max        1.000000     1.000000        1.000000           1.000000   \n",
              "\n",
              "               bmi  smoking_status       stroke  \n",
              "count  5110.000000     5110.000000  5110.000000  \n",
              "mean      0.212981        0.458969     0.048728  \n",
              "std       0.088179        0.357178     0.215320  \n",
              "min       0.000000        0.000000     0.000000  \n",
              "25%       0.154639        0.000000     0.000000  \n",
              "50%       0.207331        0.666667     0.000000  \n",
              "75%       0.257732        0.666667     0.000000  \n",
              "max       1.000000        1.000000     1.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICuY0lg5nUD"
      },
      "source": [
        "### Removing Unnecessary Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua71U2YxL5Ls"
      },
      "source": [
        "**Question 7:** From the features that you have, remove the feature(s) that is(are) irrelevant to your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8AHNqYbh5sE7"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['id', 'Residence_type'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k-KoLpH5C9R"
      },
      "source": [
        "# Building the DL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI2VtlafMBeN"
      },
      "source": [
        "**Question 8:** Now it's time to build the actual model, and observe a summary of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AZvKqqT65E0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 16]              32\n",
            "            Linear-2                   [-1, 16]             272\n",
            "            Linear-3                    [-1, 9]             153\n",
            "================================================================\n",
            "Total params: 457\n",
            "Trainable params: 457\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features= input_size, out_features=16) \n",
        "        self.fc2 = nn.Linear(in_features=16, out_features=16)   \n",
        "        self.fc3 = nn.Linear(in_features=16, out_features=output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = Model(1,9)\n",
        "summary(model, input_size=(1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD57fE2n7QP4"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGmh1x1-qH9"
      },
      "source": [
        "**Question 9:**  Now we compile the model. Here we want to measure the accuracy as well as the precision and recall to know better about the performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woSsSTEm61_U"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=,loss=,metrics=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zevRH57X8v"
      },
      "source": [
        "### Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhaEU26KMUWK"
      },
      "source": [
        "**Question 10:** Split the data and train the model\n",
        "\n",
        "We take the first columns as features and the last column as a label, then we split our dataset between training (70%) and testing (30%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsVOVfn47MLn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVvxbyPyezb3"
      },
      "source": [
        "we fit the model on 80% training data, and validate on the rest. Later we will do the final test on the test data. The training happens for 15 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrlvFubpqBeS"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqUo00lAqCZ"
      },
      "source": [
        "# Improving DL Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op2Frp44uSiX"
      },
      "source": [
        "**Question 11:** Suggest ways to improve your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImSYWQGBSz6"
      },
      "source": [
        "### Checking For Data Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHxCONODMkNN"
      },
      "source": [
        "We check for imbalance because we have a poor recall and precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bF6G8c58SOE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzZBB5GMCOld"
      },
      "source": [
        "We have a huge imbalance in the data, this is why we fix it with oversamppling and undersampling.\n",
        "\n",
        "We will oversample this time using the SMOTE() function instead of random oversampling, and this is because SMOTE will generate new data based on the data that we have, so we avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US4xON4LBX8I"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "over = SMOTE()\n",
        "x_new, y_new =\n",
        "\n",
        "\n",
        "plt.hist([y_new])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmfeUhi1ezb9"
      },
      "source": [
        "Split the balanced dataset between 90% (training and validation), 10% testing\n",
        "Then divide the 90% between 80% training and 20% validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxnYFoPZezb-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train_val, x_test, y_train_val, y_test = train_test_split(x_new, y_new, test_size=0.1, stratify=y_new)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, stratify=y_train_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgyxF74oezcA"
      },
      "source": [
        "Now we will train the model on the balanced data, and tune it on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26YTispLEm9N"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAhUAu5JezcC"
      },
      "source": [
        "Evaluate your model on the test set that you kept aside at the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utTyIgJLezcD"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfhpIaWGtz2"
      },
      "source": [
        "We see that the performance gets better when our data became balanced.\n",
        "Now we will try improving our model with other techniques that we learned through the week."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngJVLbRKG7U_"
      },
      "source": [
        "### Model Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMdcXspCHxIo"
      },
      "source": [
        "We will introduce batch normalization after each layer and then train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK78-g-hHrmq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim=10, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REDrQVWLJLs5"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "history2 = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eenpPyr_ezcH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhkSEThVKEdm"
      },
      "source": [
        "We see that we are achieving better metrics with batch normalization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d1GOfAgt4M-Q",
        "KICuY0lg5nUD",
        "AD57fE2n7QP4",
        "U5zevRH57X8v",
        "IImSYWQGBSz6",
        "ngJVLbRKG7U_",
        "mXf6cpO_KWTs"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
